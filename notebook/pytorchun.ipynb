{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorchun.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqiOnUjLmh7b"
      },
      "source": [
        "pip install transformers --quiet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY_seWKrmuJ-"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pvp_4farRZf"
      },
      "source": [
        "def seed_everything(seed):\n",
        "  np.random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "seed_everything(21)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74j1CaOXr0Jl"
      },
      "source": [
        "train = pd.read_csv(\"https://raw.githubusercontent.com/Josepholaidepetro/Gender-Based-Violence-Tweet-Classification-Challenge/main/data/Train.csv\")\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/Josepholaidepetro/Gender-Based-Violence-Tweet-Classification-Challenge/main/data/Test.csv\")\n",
        "sub = pd.read_csv('https://raw.githubusercontent.com/Josepholaidepetro/UN-Tweety-Goal-5/main/data/SampleSubmission.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5MOrmMTr0MH"
      },
      "source": [
        "X = train['tweet']\n",
        "y = train[\"type\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0eSVglor0PD"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()        \n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljIhrCEO7vrE"
      },
      "source": [
        "train_df = pd.DataFrame(X)\n",
        "train_df['type'] = y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUQTISJ1sO4W"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s4B3H4t74fbU",
        "outputId": "3d8ba2a9-a6c6-4188-ded0-bb6637d097f1"
      },
      "source": [
        "\"\"\"train_df = pd.DataFrame(X_train)\n",
        "train_df['type'] = y_train\n",
        "val_df = pd.DataFrame(X_val)\n",
        "val_df['type'] = y_val\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"train_df = pd.DataFrame(X_train)\\ntrain_df['type'] = y_train\\nval_df = pd.DataFrame(X_val)\\nval_df['type'] = y_val\""
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCS2W3gp6RLC"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz56i5fOm-82"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "  def __init__(self, df, tokenizer, max_len):\n",
        "    self.labels = df['type'].values\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "    self.texts = [text for text in df['tweet']]\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "      texts = self.texts[idx]\n",
        "      label = self.labels[idx]\n",
        "      text = self.tokenizer(texts, \n",
        "                            padding='max_length', max_length = self.max_len, truncation=True,\n",
        "                            return_tensors=\"pt\")\n",
        "\n",
        "      return text, label"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ-Ifm9EkkeP"
      },
      "source": [
        "class TextDataset(Dataset):\n",
        "  def __init__(self, df, tokenizer, max_len):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "    self.texts = [text for text in df['tweet']]\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "      texts = self.texts[idx]\n",
        "      text = self.tokenizer(texts, \n",
        "                            padding='max_length', max_length = self.max_len, truncation=True,\n",
        "                            return_tensors=\"pt\")\n",
        "\n",
        "      return text"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywakfgrQ6me-"
      },
      "source": [
        "def GBVDataloader(df, batch_size, tokenizer):\n",
        "  dataset = Dataset(df, tokenizer, 120)\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "  return dataloader\n",
        "\n",
        "def GBVTestDataloader(df, batch_size , tokenizer):\n",
        "    dataset = TextDataset(df, tokenizer, 120)\n",
        "    dataloader = DataLoader(dataset , batch_size , shuffle=False)\n",
        "    return dataloader"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnfOwatQq6yu"
      },
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_labels, dropout=0.85):\n",
        "\n",
        "      super(BertClassifier, self).__init__()\n",
        "\n",
        "      self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "      self.dropout = nn.Dropout(dropout)\n",
        "      self.linear = nn.Linear(768, n_labels)\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, input_id, mask):\n",
        "\n",
        "      _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "      dropout_output = self.dropout(pooled_output)\n",
        "      linear_output = self.linear(dropout_output)\n",
        "      final_layer = self.relu(linear_output)\n",
        "\n",
        "      return final_layer"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDJP9BtvoY_E",
        "outputId": "04b07603-06b1-4fb8-cedf-79585a2cc8de"
      },
      "source": [
        "model = BertClassifier(5)\n",
        "model.to(device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.85, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=5, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3qw6656EKpG"
      },
      "source": [
        "def train_loop(model, train_data, dataloader, optimizer, scheduler, criterion, device):\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_acc_train = 0\n",
        "  total_loss_train = 0\n",
        "\n",
        "  for train_input, train_label in tqdm(dataloader):\n",
        "\n",
        "    train_label = train_label.to(device)\n",
        "    mask = train_input['attention_mask'].to(device)\n",
        "    input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "    output = model(input_id, mask)\n",
        "\n",
        "    batch_loss = criterion(output, train_label)\n",
        "    total_loss_train += batch_loss.item()\n",
        "\n",
        "    acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "    total_acc_train += acc\n",
        "\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "  return total_loss_train / len(train_data), total_acc_train / len(train_data)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vQSh3Yo2N4V"
      },
      "source": [
        "def eval_loop(model, val_data, dataloader, criterion, device):\n",
        "  total_acc_val = 0\n",
        "  total_loss_val = 0\n",
        "  \n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for val_input, val_label in dataloader:\n",
        "\n",
        "      val_label = val_label.to(device)\n",
        "      mask = val_input['attention_mask'].to(device)\n",
        "      input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "      output = model(input_id, mask)\n",
        "\n",
        "      batch_loss = criterion(output, val_label)\n",
        "      total_loss_val += batch_loss.item()\n",
        "      \n",
        "      acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "      total_acc_val += acc\n",
        "  return total_loss_val / len(val_data), total_acc_val / len(val_data)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTEznlVS1_ep"
      },
      "source": [
        "def train(model, train_data, learning_rate, batch_size, epochs, epsilon):\n",
        "  \n",
        "  # loss fn\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  for epoch_num in range(epochs):      \n",
        "  \n",
        "    fold = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "  \n",
        "    for step, (train, valid) in enumerate(fold.split(train_data['tweet'], train_data[\"type\"])):\n",
        "  \n",
        "      train_dataloader = GBVDataloader(train_data.iloc[train], batch_size, tokenizer)\n",
        "      val_data_loader = GBVDataloader(train_data.iloc[valid], batch_size, tokenizer)\n",
        "      # Create the optimizer\n",
        "      optimizer = AdamW(model.parameters(),\n",
        "            lr=learning_rate,    # Default learning rate\n",
        "            eps=epsilon)   # Default epsilon value\n",
        "      \n",
        "      # Set up the learning rate scheduler\n",
        "      total_steps = (len(train_dataloader) // batch_size) * epochs\n",
        "      scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                      num_warmup_steps=0, # Default value\n",
        "                                      num_training_steps=total_steps)\n",
        "        \n",
        "      train_loss, train_acc = train_loop(model, train_data.iloc[train], train_dataloader, optimizer, scheduler, criterion, device)\n",
        "      print(f\"Train accuracy {train_acc} ,Train Loss {train_loss}\")\n",
        "      val_loss, val_acc = eval_loop(model, train_data.iloc[valid], val_data_loader, criterion, device)\n",
        "      print(f\"Validation accuracy {val_acc} ,Validation Loss {val_loss}\")\n",
        "      "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf3nnN3Nt0J5"
      },
      "source": [
        "EPOCHS = 2\n",
        "LR = 3e-5\n",
        "batch_size = 30\n",
        "epsilon = 1e-8"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW79WGEk1rKg",
        "outputId": "811e1ab9-4874-4e52-cb12-2aef73daac8b"
      },
      "source": [
        "train(model, train_data=train_df, learning_rate=LR, batch_size=batch_size, epochs=EPOCHS, epsilon=epsilon)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1058/1058 [19:29<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 0.9877679697351829 ,Train Loss 0.0012601745032165973\n",
            "Validation accuracy 0.992938209331652 ,Validation Loss 0.0011199553125025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1058/1058 [19:28<00:00,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 0.9888398486759142 ,Train Loss 0.001249152787727813\n",
            "Validation accuracy 0.992938209331652 ,Validation Loss 0.0010196314047495594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1058/1058 [19:28<00:00,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 0.9895334174022699 ,Train Loss 0.0012510890628451205\n",
            "Validation accuracy 0.9935687263556116 ,Validation Loss 0.000889423011591125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1058/1058 [19:26<00:00,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 0.9924022698612862 ,Train Loss 0.0010393295653020537\n",
            "Validation accuracy 0.9939470365699874 ,Validation Loss 0.0007461187458756552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1058/1058 [19:30<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 0.991046658259773 ,Train Loss 0.0010289893558897455\n",
            "Validation accuracy 0.9918032786885246 ,Validation Loss 0.0008569205322347727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1058/1058 [19:31<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 0.9958701134930643 ,Train Loss 0.0005614105790462241\n",
            "Validation accuracy 0.9967213114754099 ,Validation Loss 0.0006657846922891741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1058/1058 [19:31<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 0.9956179066834805 ,Train Loss 0.0005808038504869126\n",
            "Validation accuracy 0.9972257250945775 ,Validation Loss 0.0005158706531808608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1058/1058 [19:35<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 0.9959331651954603 ,Train Loss 0.0004431900164556172\n",
            "Validation accuracy 0.998108448928121 ,Validation Loss 0.00034611098147998686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1058/1058 [19:33<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 0.9978877679697352 ,Train Loss 0.00033483479395957\n",
            "Validation accuracy 0.9987389659520807 ,Validation Loss 0.00021858692906254052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1058/1058 [19:35<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 0.9979823455233291 ,Train Loss 0.00032513432481198567\n",
            "Validation accuracy 0.9994955863808322 ,Validation Loss 0.00012892679413271322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjPVEaqbk8ff"
      },
      "source": [
        "testdataloader = GBVTestDataloader(test, 1, tokenizer)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImpFHBSyk_rv"
      },
      "source": [
        "def pred_loop(model, dataloader, device):\n",
        "  \n",
        "  pred_proba = []\n",
        "  \n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for val_input in dataloader:\n",
        "\n",
        "      mask = val_input['attention_mask'].to(device)\n",
        "      input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "      output = model(input_id, mask)\n",
        "\n",
        "      pred_proba.append(output)\n",
        "\n",
        "  return pred_proba"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NZJMH40f1kJ"
      },
      "source": [
        "pred_outputs = pred_loop(model, testdataloader, device=device)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_X9LDByf841"
      },
      "source": [
        "dat = []\n",
        "for i in pred_outputs:\n",
        "    dat.append(i.flatten().tolist())"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkUJjOXjiCQf"
      },
      "source": [
        "pred = [np.argmax(i) for i in dat]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0XpgwGrkyl0"
      },
      "source": [
        "final = le.inverse_transform(pred)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj8rqKqIkDZt"
      },
      "source": [
        "sub['type'] = final"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZNV2bQ3kWkK",
        "outputId": "13444753-c6c5-4cec-9416-c977f07c53b2"
      },
      "source": [
        "sub['type'].value_counts()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sexual_violence                 11340\n",
              "Harmful_Traditional_practice     3028\n",
              "emotional_violence                690\n",
              "economic_violence                 396\n",
              "Physical_violence                 127\n",
              "Name: type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2R192mHlIXW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}